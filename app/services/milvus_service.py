import logging
import json
import time
from typing import List, Dict, Any, Optional
from pymilvus import Collection, CollectionSchema, FieldSchema, DataType, connections, utility

# Configuration du logger
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

class MilvusService:
    def __init__(
        self, 
        collection_name: str, 
        dim: int = 1024,
        host: str = "10.100.212.133", 
        port: int = 19530,
        timeout: int = 30,
        max_retries: int = 3
    ):
        """
        Initialise le service Milvus avec des options de connexion avanc√©es.
        
        Args:
            collection_name: Nom de la collection Milvus
            dim: Dimension des vecteurs d'embedding
            host: Adresse du serveur Milvus
            port: Port du serveur Milvus
            timeout: D√©lai d'attente pour la connexion
            max_retries: Nombre maximum de tentatives de connexion
        """
        self.collection_name = collection_name
        self.dim = dim
        self.host = host
        self.port = port
        self.timeout = timeout
        self.max_retries = max_retries
        
        self.collection = None
        
        # M√©thode de connexion am√©lior√©e
        self._connect_to_milvus()
        
        # V√©rifier/cr√©er la collection
        self._ensure_collection()

    def _connect_to_milvus(self):
        """
        √âtablit la connexion avec le serveur Milvus distant avec des tentatives multiples.
        """
        import time
        
        for attempt in range(self.max_retries):
            try:
                logger.info(f"Tentative de connexion √† Milvus ({attempt + 1}/{self.max_retries})...")
                
                connections.connect(
                    alias="default", 
                    host=self.host, 
                    port=str(self.port),
                    timeout=self.timeout
                )
                
                # V√©rifier la connexion
                utility.list_collections()
                
                logger.info(f"‚úÖ Connect√© au serveur Milvus sur {self.host}:{self.port}")
                return
            
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è √âchec de connexion (Tentative {attempt + 1}/{self.max_retries}): {e}")
                
                # Backoff exponentiel
                time.sleep(2 ** attempt)
        
        # Si toutes les tentatives √©chouent
        error_msg = f"‚ùå Impossible de se connecter au serveur Milvus apr√®s {self.max_retries} tentatives"
        logger.error(error_msg)
        raise ConnectionError(error_msg)

    def _ensure_collection(self):
        """
        S'assure que la collection existe avec le bon sch√©ma.
        Cr√©e la collection si n√©cessaire.
        """
        try:
            # V√©rifier si la collection existe
            if utility.has_collection(self.collection_name):
                self.collection = Collection(self.collection_name)
                logger.info(f"Collection existante '{self.collection_name}' charg√©e")
                
                # V√©rifier si le sch√©ma est compatible
                if not self._is_schema_compatible(self.collection.schema):
                    logger.warning(f"Sch√©ma incompatible, recr√©ation de la collection '{self.collection_name}'")
                    utility.drop_collection(self.collection_name)
                    self._define_and_create_collection()
            else:
                logger.info(f"Collection '{self.collection_name}' non trouv√©e, cr√©ation en cours...")
                self._define_and_create_collection()
        
        except Exception as e:
            logger.error(f"Erreur lors de la v√©rification/cr√©ation de la collection: {e}")
            raise

    def _define_and_create_collection(self):
        """
        D√©finit et cr√©e la collection avec le sch√©ma appropri√©.
        """
        try:
            # D√©finir les champs
            fields = [
                FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=True),
                FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=self.dim),
                FieldSchema(name="text", dtype=DataType.VARCHAR, max_length=65535),
                FieldSchema(name="document_id", dtype=DataType.VARCHAR, max_length=100),
                FieldSchema(name="chunk_id", dtype=DataType.VARCHAR, max_length=100),
                FieldSchema(name="page_number", dtype=DataType.INT64),
                FieldSchema(name="filename", dtype=DataType.VARCHAR, max_length=65535),
                FieldSchema(name="metadata", dtype=DataType.VARCHAR, max_length=65535)
            ]
            
            # Cr√©er le sch√©ma
            schema = CollectionSchema(fields)
            
            # Cr√©er la collection
            self.collection = Collection(name=self.collection_name, schema=schema)
            logger.info(f"Collection '{self.collection_name}' cr√©√©e avec succ√®s")
            
            # Cr√©er l'index
            index_params = {
                "index_type": "HNSW",
                "metric_type": "COSINE",
                "params": {
                    "M": 16,
                    "efConstruction": 200
                }
            }
            
            self.collection.create_index(field_name="embedding", index_params=index_params)
            logger.info("Index cr√©√© sur le champ 'embedding'")
            
        except Exception as e:
            logger.error(f"Erreur lors de la cr√©ation de la collection: {e}")
            raise

    def _is_schema_compatible(self, existing_schema):

        """
        V√©rifie si le sch√©ma existant est compatible avec nos besoins.
        """
        try:
            # V√©rifier la dimension du vecteur d'embedding
            for field in existing_schema.fields:
                if field.name == "embedding" and field.dtype == DataType.FLOAT_VECTOR:
                    field_params = getattr(field, "params", {})
                    if isinstance(field_params, dict) and field_params.get("dim") == self.dim:
                        return True
            return False
        except Exception as e:
            logger.error(f"Erreur lors de la v√©rification du sch√©ma: {e}")
            return False

    def insert_documents(self, embeddings, texts=None, metadata_list=None):
        """
        Ins√®re des embeddings dans la collection Milvus.
        Version corrig√©e pour g√©rer le sch√©ma avec 8 champs (id, embedding, text, document_id, chunk_id, page_number, filename, metadata).
        
        Args:
            embeddings: Liste des vecteurs d'embedding
            texts: Liste des textes correspondants (optionnel)
            metadata_list: Liste des m√©tadonn√©es (optionnel)
        """
        if not embeddings:
            logger.warning("Aucun embedding √† ins√©rer")
            return
            
        try:
            # V√©rifier la dimension des embeddings
            if len(embeddings[0]) != self.dim:
                logger.warning(f"Dimension des embeddings ({len(embeddings[0])}) diff√©rente de celle attendue ({self.dim})")
                logger.info("Adaptation de la dimension des embeddings...")
                embeddings = self._adjust_embedding_dimension(embeddings)
            
            # V√©rifier le sch√©ma de la collection
            schema = self.collection.schema
            field_names = [field.name for field in schema.fields if not field.auto_id]
            
            logger.info(f"üîç Champs du sch√©ma (sans auto_id): {field_names}")
            logger.info(f"üìä Nombre de champs √† remplir: {len(field_names)}")
            
            # Pr√©parer les donn√©es dans l'ordre exact du sch√©ma
            # IMPORTANT: Ne pas inclure le champ 'id' car il est auto-g√©n√©r√©
            data = []
            
            # 1. embedding (obligatoire)
            data.append(embeddings)
            
            # 2. text (obligatoire)
            if texts:
                if len(texts) != len(embeddings):
                    raise ValueError("Le nombre de textes doit correspondre au nombre d'embeddings")
                data.append(texts)
            else:
                data.append([""] * len(embeddings))
            
            # 3-8. Autres champs selon le sch√©ma avec FILENAME
            if metadata_list:
                if len(metadata_list) != len(embeddings):
                    raise ValueError("Le nombre de m√©tadonn√©es doit correspondre au nombre d'embeddings")
                
                # Extraire les champs de m√©tadonn√©es dans l'ordre du sch√©ma
                document_ids = []
                chunk_ids = []
                page_numbers = []
                filenames = []  # ‚Üê NOUVEAU CHAMP
                metadata_json = []
                
                for meta in metadata_list:
                    # Assurer que nous avons des valeurs valides
                    document_id = meta.get("document_id", f"doc_{int(time.time())}")
                    chunk_id = meta.get("chunk_id", f"chunk_{int(time.time())}")
                    page_number = meta.get("page_number", 1)
                    
                    # Extraction du filename avec fallbacks
                    filename = meta.get("filename") or meta.get("source") or meta.get("file_name") or meta.get("document_name")
                    if not filename:
                        filename = f"Document_{document_id[:8]}"
                    
                    # Nettoyer le filename
                    if isinstance(filename, str):
                        # Enlever les chemins
                        if "/" in filename:
                            filename = filename.split("/")[-1]
                        elif "\\" in filename:
                            filename = filename.split("\\")[-1]
                        
                        # Limiter la longueur pour VARCHAR
                        if len(filename) > 200:  # S√©curit√© pour VARCHAR
                            filename = filename[:197] + "..."
                    else:
                        filename = str(filename)
                    
                    # Validation des types
                    if not isinstance(document_id, str):
                        document_id = str(document_id)
                    if not isinstance(chunk_id, str):
                        chunk_id = str(chunk_id)
                    if not isinstance(page_number, int):
                        try:
                            page_number = int(page_number)
                        except (ValueError, TypeError):
                            page_number = 1
                    
                    document_ids.append(document_id)
                    chunk_ids.append(chunk_id)
                    page_numbers.append(page_number)
                    filenames.append(filename)  # ‚Üê AJOUTER LE FILENAME
                    
                    # Convertir les m√©tadonn√©es compl√®tes en JSON
                    try:
                        metadata_json.append(json.dumps(meta, ensure_ascii=False))
                    except Exception as e:
                        logger.warning(f"Erreur lors de la s√©rialisation JSON: {e}")
                        metadata_json.append("{}")
                
                # Ajouter dans l'ordre du sch√©ma : document_id, chunk_id, page_number, filename, metadata
                data.extend([document_ids, chunk_ids, page_numbers, filenames, metadata_json])
            else:
                # Valeurs par d√©faut pour tous les champs manquants
                default_count = len(embeddings)
                data.extend([
                    [f"doc_{i}_{int(time.time())}" for i in range(default_count)],  # document_id
                    [f"chunk_{i}_{int(time.time())}" for i in range(default_count)], # chunk_id  
                    [1] * default_count,  # page_number
                    [f"Document_{i}" for i in range(default_count)],  # filename ‚Üê NOUVEAU
                    ["{}"] * default_count  # metadata
                ])
            
            # V√©rification finale
            expected_fields = len([f for f in schema.fields if not f.auto_id])
            provided_fields = len(data)
            
            logger.info(f"‚úÖ V√©rification: {provided_fields} listes de donn√©es pour {expected_fields} champs requis")
            
            if provided_fields != expected_fields:
                raise ValueError(f"Nombre de champs incorrects: fourni {provided_fields}, attendu {expected_fields}")
            
            # Debug: afficher les tailles et quelques exemples
            for i, field_data in enumerate(data):
                field_name = field_names[i] if i < len(field_names) else f"field_{i}"
                sample = field_data[0] if field_data else "N/A"
                logger.debug(f"  {field_name}: {len(field_data)} √©l√©ments (ex: {sample})")
            
            # Ins√©rer les donn√©es
            logger.info(f"üöÄ Insertion de {len(embeddings)} documents...")
            insert_result = self.collection.insert(data)
            logger.info(f"‚úÖ Insertion r√©ussie: {insert_result.insert_count} enregistrements")
            
            # Flush pour s'assurer que les donn√©es sont persistantes
            self.collection.flush()
            logger.info("üíæ Donn√©es persist√©es avec succ√®s")
            
            return insert_result
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'insertion des documents: {e}")
            logger.error(f"üìä Debug - Nombre d'embeddings: {len(embeddings)}")
            logger.error(f"üìä Debug - Nombre de textes: {len(texts) if texts else 0}")
            logger.error(f"üìä Debug - Nombre de m√©tadonn√©es: {len(metadata_list) if metadata_list else 0}")
            
            # Debug suppl√©mentaire pour le sch√©ma
            try:
                schema = self.collection.schema
                logger.error(f"üìã Sch√©ma attendu: {[f.name for f in schema.fields]}")
                logger.error(f"üìä Champs non auto-g√©n√©r√©s: {[f.name for f in schema.fields if not f.auto_id]}")
            except:
                pass

    def _adjust_embedding_dimension(self, embeddings):
        """
        Ajuste la dimension des embeddings pour correspondre √† celle attendue par Milvus.
        
        Args:
            embeddings: Liste des vecteurs d'embedding
            
        Returns:
            Liste des vecteurs d'embedding ajust√©s
        """
        adjusted_embeddings = []
        for embedding in embeddings:
            current_dim = len(embedding)
            
            if current_dim < self.dim:
                # Padding pour augmenter la dimension
                adjusted = embedding + [0.0] * (self.dim - current_dim)
            elif current_dim > self.dim:
                # Troncature pour r√©duire la dimension
                adjusted = embedding[:self.dim]
            else:
                adjusted = embedding
                
            adjusted_embeddings.append(adjusted)
            
        return adjusted_embeddings
    

    def search(self, query_embedding, top_k=5):

        """
        Recherche les embeddings les plus similaires dans Milvus.
        Compatible avec les collections existantes qui peuvent avoir des sch√©mas diff√©rents.
        
        Args:
            query_embedding: Vecteur d'embedding de requ√™te
            top_k: Nombre de r√©sultats √† retourner
        
        Returns:
            Liste de dictionnaires contenant le texte et le score de similarit√©
        """
        if not self.collection:
            raise Exception("Collection not initialized.")
        
        # V√©rification de la dimension
        if len(query_embedding) != self.dim:
            raise ValueError(f"Query embedding dimension should be {self.dim}")
        
        try:
            # Chargement de la collection pour s'assurer que l'index est disponible
            self.collection.load()
            
            # R√©cup√©rer les champs disponibles dans la collection
            schema = self.collection.schema
            available_fields = [field.name for field in schema.fields]
            logger.info(f"Champs disponibles dans la collection: {available_fields}")
            
            # Filtrer les champs de sortie en fonction des champs disponibles
            base_output_fields = ["text"]
            additional_fields = ["document_id", "page_number", "filename", "chunk_id"]
            
            # Ne conserver que les champs qui existent r√©ellement dans la collection
            output_fields = [field for field in base_output_fields if field in available_fields]
            output_fields += [field for field in additional_fields if field in available_fields]
            
            logger.info(f"Utilisation des champs de sortie: {output_fields}")
            
            search_params = {
                "metric_type": "COSINE",
                "params": {"nprobe": 10}
            }
            
            # Effectuer la recherche avec les champs disponibles
            results = self.collection.search(
                data=[query_embedding], 
                anns_field="embedding", 
                param=search_params, 
                limit=top_k,
                output_fields=output_fields if output_fields else None
            )
            
            # Formater les r√©sultats pour les rendre plus faciles √† utiliser
            formatted_results = []
            
            for hit in results[0]:
                try:
                    result = {"score": hit.distance}
                    
                    # R√©cup√©rer les attributs disponibles de mani√®re s√©curis√©e
                    entity = hit.entity
                    for field in output_fields:
                        try:
                            # Utiliser getattr avec une valeur par d√©faut
                            value = getattr(entity, field, None)
                            result[field] = value
                        except Exception as field_error:
                            logger.warning(f"Impossible d'acc√©der au champ {field}: {field_error}")
                    
                    # Assurer qu'il y a au moins un champ 'text'
                    if "text" not in result or not result["text"]:
                        result["text"] = "Texte non disponible"
                    
                    formatted_results.append(result)
                    
                except Exception as hit_error:
                    logger.error(f"Erreur lors de l'extraction d'un r√©sultat: {hit_error}")
                    # Ajouter un r√©sultat minimal en cas d'erreur
                    formatted_results.append({
                        "text": "Erreur de r√©cup√©ration du texte",
                        "score": hit.distance
                    })
            
            logger.info(f"Found {len(formatted_results)} results for the query.")
            return formatted_results
            
        except Exception as e:
            logger.error(f"Erreur lors de la recherche: {e}")
            raise
        finally:
            # Lib√©rer la m√©moire
            try:
                self.collection.release()
            except Exception as release_error:
                logger.warning(f"Impossible de lib√©rer la collection: {release_error}")

    def insert_documents_with_metadata(self, embeddings, texts, metadata_list):
            """
            Adapte l'insertion avec m√©tadonn√©es vers la m√©thode existante.
            """
            logger.info(f"Insertion dans Milvus de {len(embeddings)} embeddings avec textes et m√©tadonn√©es")
            return self.insert_documents(embeddings, texts, metadata_list)

    def get_collection_stats(self):
        """Retourne des statistiques sur la collection."""
        try:
            if not self.collection:
                return {"error": "Collection non initialis√©e"}
                
            stats = {
                "name": self.collection_name,
                "dimension": self.dim,
                "entity_count": self.collection.num_entities
            }
            
            return stats
            
        except Exception as e:
            logger.error(f"Erreur lors de la r√©cup√©ration des statistiques: {e}")
            return {"error": str(e)}
        
    def get_documents_by_filter(self, filter_expr: str, limit: int = 10) -> List[Dict[str, Any]]:
        """
        R√©cup√®re les documents correspondant √† une expression de filtre.
        
        Args:
            filter_expr: Expression de filtre Milvus
            limit: Nombre maximum de documents √† retourner
            
        Returns:
            Liste de documents (dictionnaires)
        """
        try:
            # Charger la collection
            self.collection.load()
            
            # Ex√©cuter la requ√™te avec filtrage
            results = self.collection.query(
                expr=filter_expr,
                output_fields=["text", "metadata"],
                limit=limit
            )
            
            results = [result.entity for result in results]
            
            # Convertir les r√©sultats en dictionnaires
            documents = []
            for result in results:
                document = {
                    "text": result["text"],
                    "metadata": json.loads(result["metadata"])  
                }
                documents.append(document)
            
            return documents

        except Exception as e:
            logger.error(f"Erreur lors de la r√©cup√©ration des documents par filtre: {e}")
            return []
        finally:
            # Lib√©rer la collection
            self.collection.release()


# Point d'entr√©e pour les tests
if __name__ == "__main__":
    try:
        # Test de connexion
        service = MilvusService(
            collection_name="test_collection", 
            dim=1024,
            host="10.100.212.133",
            port=19530
        )
        
        # V√©rifier les statistiques de la collection
        stats = service.get_collection_stats()
        print(f"Statistiques de la collection: {json.dumps(stats, indent=2)}")
        
    except Exception as e:
        print(f"Erreur lors du test de connexion Milvus : {e}")